{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tberg12/cse291spr21/blob/main/assignment0/assignment0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMSuJOhhqa4K"
   },
   "source": [
    "# Project 0 - Language Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJqPBpc-Nw-X"
   },
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6u8fFzd-q-1w"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "paBj08mYNlHS",
    "outputId": "e8342ce0-633d-46ca-dfae-eef5fa33995b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/cse291spr21/assignment0/'\n",
      "/Users/tritruong/Documents/cse291spr21/assignment0\n"
     ]
    }
   ],
   "source": [
    "%cd /content/cse291spr21/assignment0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k79jLFYaOpeb"
   },
   "source": [
    "## Task II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X447pK1STsT9"
   },
   "source": [
    "### 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-fA0cAEYTiC"
   },
   "source": [
    "Train an recurrent neural network (RNN) based language model (LM) on the WikiText-2 dataset. Report the final perplexity on the test set. (_Hint_: You should be able to reach a perplexity lower than 150 in 10 epochs, which should take around 10 minutes if you are using a GPU on Colab.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WK8LMutLqKdx",
    "outputId": "57daf374-594d-4dbf-cf43-2e3b599c9595"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path = ./data/wikitext-2/train.txt\n",
      "path = ./data/wikitext-2/valid.txt\n",
      "path = ./data/wikitext-2/test.txt\n",
      "| epoch   1 |   200/ 3052 batches | lr 20.00 | ms/batch 106.97 | loss  3.13 | ppl    22.82\n",
      "| epoch   1 |   400/ 3052 batches | lr 20.00 | ms/batch 110.43 | loss  2.15 | ppl     8.55\n",
      "| epoch   1 |   600/ 3052 batches | lr 20.00 | ms/batch 110.86 | loss  1.89 | ppl     6.60\n",
      "| epoch   1 |   800/ 3052 batches | lr 20.00 | ms/batch 117.18 | loss  1.75 | ppl     5.75\n",
      "| epoch   1 |  1000/ 3052 batches | lr 20.00 | ms/batch 123.57 | loss  1.66 | ppl     5.26\n",
      "| epoch   1 |  1200/ 3052 batches | lr 20.00 | ms/batch 135.93 | loss  1.61 | ppl     5.02\n",
      "| epoch   1 |  1400/ 3052 batches | lr 20.00 | ms/batch 153.70 | loss  1.58 | ppl     4.85\n",
      "| epoch   1 |  1600/ 3052 batches | lr 20.00 | ms/batch 117.48 | loss  1.56 | ppl     4.74\n",
      "| epoch   1 |  1800/ 3052 batches | lr 20.00 | ms/batch 115.81 | loss  1.52 | ppl     4.59\n",
      "| epoch   1 |  2000/ 3052 batches | lr 20.00 | ms/batch 115.69 | loss  1.51 | ppl     4.54\n",
      "| epoch   1 |  2200/ 3052 batches | lr 20.00 | ms/batch 114.70 | loss  1.50 | ppl     4.47\n",
      "| epoch   1 |  2400/ 3052 batches | lr 20.00 | ms/batch 129.11 | loss  1.48 | ppl     4.39\n",
      "| epoch   1 |  2600/ 3052 batches | lr 20.00 | ms/batch 121.63 | loss  1.47 | ppl     4.36\n",
      "| epoch   1 |  2800/ 3052 batches | lr 20.00 | ms/batch 112.71 | loss  1.47 | ppl     4.33\n",
      "| epoch   1 |  3000/ 3052 batches | lr 20.00 | ms/batch 114.13 | loss  1.46 | ppl     4.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 389.87s | valid loss  1.32 | valid ppl     3.73\n",
      "-----------------------------------------------------------------------------------------\n",
      "=========================================================================================\n",
      "| End of training | test loss  1.31 | test ppl     3.71\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "!python3 main.py --data \"./data/wikitext-2\" --epoch 1 --batch_size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 3343 batches | lr 20.00 | ms/batch 252.43 | loss  3.43 | ppl    30.76\n",
      "| epoch   1 |   400/ 3343 batches | lr 20.00 | ms/batch 265.77 | loss  2.67 | ppl    14.51\n",
      "| epoch   1 |   600/ 3343 batches | lr 20.00 | ms/batch 269.92 | loss  2.03 | ppl     7.65\n",
      "| epoch   1 |   800/ 3343 batches | lr 20.00 | ms/batch 272.58 | loss  1.63 | ppl     5.12\n",
      "| epoch   1 |  1000/ 3343 batches | lr 20.00 | ms/batch 270.60 | loss  1.36 | ppl     3.88\n",
      "| epoch   1 |  1200/ 3343 batches | lr 20.00 | ms/batch 272.04 | loss  1.02 | ppl     2.77\n",
      "| epoch   1 |  1400/ 3343 batches | lr 20.00 | ms/batch 272.79 | loss  0.71 | ppl     2.03\n",
      "| epoch   1 |  1600/ 3343 batches | lr 20.00 | ms/batch 294.62 | loss  0.50 | ppl     1.65\n"
     ]
    }
   ],
   "source": [
    "!python3 main.py --data \"./data/shakespeare\" --epoch 50 --batch_size 40 --nlayers 3 --nhid 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Generated 0/1000 words\n",
      "| Generated 100/1000 words\n",
      "| Generated 200/1000 words\n",
      "| Generated 300/1000 words\n",
      "| Generated 400/1000 words\n",
      "| Generated 500/1000 words\n",
      "| Generated 600/1000 words\n",
      "| Generated 700/1000 words\n",
      "| Generated 800/1000 words\n",
      "| Generated 900/1000 words\n"
     ]
    }
   ],
   "source": [
    "!python3 generate.py --data \"./data/shakespeare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the world away:Let those whom nature hath not made for store,Harsh, featureless for a look,Poor beauty's form in table of my heart,Which in thy breast doth live, as thine in me,How can I then be elder than thou hadst before?No love, my love, my slumbers should be broken,While shadows like to thee do mock my sight?Is it thy spirit that thou send'st from theeSo far from home into my deeds to pry,To find out shames and idle hours in me,The scope and tenure of thy jealousy?O no, thy love though much, is not so great,It is my love that keeps mine eye and loss,Bark what strained touches rhetoric can lend,Thou truly fair, wert truly sympathized,In true planter by thy deeds,Then churls their thoughts (although their eyes were kind)To thy fair flower add the rank smell of weeds:But why thy odour matcheth not thy show,The soil is this, that thou dost common grow.70That thou art blamed shall not be thy defect,For slander's mark was ever yet the fair,The ornament of beauty is suspect,A crow that f"
     ]
    }
   ],
   "source": [
    "!cat generated.txt"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNTvyFFqlKbHly0YTCwxh6i",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "cse291-project0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
